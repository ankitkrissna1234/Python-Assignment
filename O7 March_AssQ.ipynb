{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e576ed-330b-471c-8397-dbdbdf39a9c5",
   "metadata": {},
   "source": [
    "1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e35ad0-7e73-4f00-9fe6-77bd415c47dc",
   "metadata": {},
   "source": [
    "The three measures of central tendency are:                                                                             \n",
    "\n",
    "i) Mean: The mean is the most commonly used measure of central tendency. It is calculated by summing up all the values in a dataset and then dividing the sum by the total number of values. The mean is sensitive to extreme values and can be affected by outliers.                                                                                                   \n",
    "\n",
    "ii) Median: The median is the middle value in a dataset when the values are arranged in ascending or descending order. If there is an even number of values, the median is the average of the two middle values. The median is less affected by extreme values and outliers compared to the mean and is often preferred when dealing with skewed distributions.         \n",
    "\n",
    "iii) Mode: The mode represents the most frequently occurring value(s) in a dataset. It can be useful when dealing with        categorical or discrete data, where the frequency of occurrence is important. Unlike the mean and median, the mode can be used with nominal data, where there is no inherent order to the categories.                                         \n",
    "\n",
    "These measures provide different perspectives on the central tendency of a dataset and are used to summarize and describe the data distribution.                                                                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d30acb-c035-448c-af94-9f59c8dff0b9",
   "metadata": {},
   "source": [
    "2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9221bc98-f736-48e1-a3ce-9bacda670a88",
   "metadata": {},
   "source": [
    "The mean, median, and mode are all measures of central tendency, but they differ in how they capture the typical or central value of a dataset. Here's a breakdown of their differences and how they are used:                             \n",
    "\n",
    "i) Mean: The mean is calculated by summing up all the values in a dataset and then dividing by the total number of values. It represents the average value and is sensitive to extreme values or outliers. The mean is commonly used when the data is numeric and follows a roughly symmetric distribution. It provides a measure of the central value that considers all the data points equally.                                                                                 \n",
    "\n",
    "ii) Median: The median is the middle value in a dataset when the values are arranged in ascending or descending order. If there is an even number of values, the median is the average of the two middle values. The median is less affected by extreme values or outliers compared to the mean. It is often used when the data is skewed or has outliers, as it represents the value that divides the dataset into two equal halves. The median is resistant to extreme values and provides a measure of the central value that is not influenced by a few extreme observations.                           \n",
    "\n",
    "iii) Mode: The mode represents the most frequently occurring value(s) in a dataset. It is used when dealing with categorical or discrete data, where the frequency of occurrence is important. The mode can also be used with numerical data, although it may not always exist or be unique. Unlike the mean and median, the mode does not provide a measure of the central value on a numerical scale but instead indicates the most common category or value.                         \n",
    "\n",
    "These measures of central tendency provide different ways to summarize and understand the central value of a dataset. Choosing the appropriate measure depends on the nature of the data, the distribution, and the presence of outliers or extreme values. In practice, it is often useful to consider multiple measures of central tendency to gain a comprehensive understanding of the dataset.                                                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f023052-07aa-4943-873b-b3eabf119b2b",
   "metadata": {},
   "source": [
    "3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732930e7-542a-47f3-aefd-afb94063e1bb",
   "metadata": {},
   "source": [
    "To calculate the three measures of central tendency (mean, median, and mode) for the given height data [178, 177, 176, 177, 178.2, 178, 175, 179, 180, 175, 178.9, 176.2, 177, 172.5, 178, 176.5], we can follow these steps:                 \n",
    "\n",
    "Mean:                                                                                                                   \n",
    "To calculate the mean, sum up all the values and divide the sum by the total number of values:                         \n",
    "Mean = (178 + 177 + 176 + 177 + 178.2 + 178 + 175 + 179 + 180 + 175 + 178.9 + 176.2 + 177 + 172.5 + 178 + 176.5) / 16\n",
    "Mean = 2797.3 / 16                                                                                                     \n",
    "Mean ≈ 174.83125                                                                                                       \n",
    "\n",
    "Median:                                                                                                                 \n",
    "To find the median, first arrange the data in ascending order:                                                         \n",
    "172.5, 175, 175, 176, 176.2, 176.5, 177, 177, 178, 178, 178, 178.2, 178.9, 179, 180\n",
    "As the data contains 16 values, the median will be the average of the two middle values:                               \n",
    "Median = (176 + 176.2) / 2                                                                                             \n",
    "Median ≈ 176.1                                                                                                         \n",
    "\n",
    "Mode:                                                                                                                   \n",
    "The mode represents the most frequently occurring value(s) in the dataset. In this case, there is no single mode as multiple values appear more than once with the same frequency. The modes for this dataset are 175, 177, 178, and 178.2, each occurring twice.                                                                                                   \n",
    "\n",
    "Therefore, the three measures of central tendency for the given height data are:                                       \n",
    "Mean ≈ 174.83125                                                                                                       \n",
    "Median ≈ 176.1                                                                                                         \n",
    "Mode: 175, 177, 178, 178.2                                                                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb1429d-0b56-4cdb-9f1f-dc8822c71f75",
   "metadata": {},
   "source": [
    "4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c5f668-02bf-4023-b5de-5753de33af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015e5cd0-1208-453f-ac64-8d5b67bb89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [178, 177, 176, 177, 178.2, 178, 175, 179, 180, 175, 178.9, 176.2, 177, 172.5, 178, 176.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2434bc72-51e0-43bd-94c1-10a69348e019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7885814036548633"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67723a44-ede0-4ea0-a836-17f297ee64bd",
   "metadata": {},
   "source": [
    "5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0845233-7190-4245-b1df-a63f850fb4a8",
   "metadata": {},
   "source": [
    "Measures of dispersion, such as range, variance, and standard deviation, are used to describe the spread or variability of a dataset. They provide information about how much the values in the dataset deviate from the central tendency measures, such as the mean or median. Here's an example to illustrate the use of these measures:                       \n",
    "\n",
    "Consider a dataset representing the daily temperatures in Celsius for a particular city over a week: [25, 27, 23, 26, 28, 24, 26]                                                                                                             \n",
    "\n",
    "Range: The range is the simplest measure of dispersion and represents the difference between the maximum and minimum values in the dataset. In this example, the range is calculated as 28 - 23 = 5. The range provides an indication of the spread of values in the dataset but is sensitive to outliers and extreme values.                                       \n",
    "\n",
    "Variance: Variance measures the average squared deviation from the mean. It quantifies the overall variability in the dataset. To calculate the variance, first, find the mean of the dataset, which in this case is (25 + 27 + 23 + 26 + 28 + 24 + 26) / 7 = 25.71. Then, subtract the mean from each value, square the differences, and calculate the average. The variance for this example is approximately 2.81.                                                                       \n",
    "\n",
    "Standard Deviation: The standard deviation is the square root of the variance. It provides a measure of the spread in the original unit of measurement (Celsius in this case). To find the standard deviation, take the square root of the variance. For this example, the standard deviation is approximately 1.67.                                               \n",
    "\n",
    "In this example, the range gives a rough estimate of the spread of values, but it does not take into account the individual deviations from the mean. The variance and standard deviation provide more precise measures of dispersion, taking into account the squared deviations from the mean. The standard deviation, in particular, is commonly used as it has the same unit of measurement as the original data, making it more interpretable.                                   \n",
    "\n",
    "By using these measures of dispersion, we can quantify and describe the spread of the dataset, providing insights into the variability of the values beyond the central tendency.                                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c72f82c-aea9-433a-9c28-7d492372ac22",
   "metadata": {},
   "source": [
    "6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff145cfe-2774-4353-aca0-715386e0f837",
   "metadata": {},
   "source": [
    "A Venn diagram is a visual representation of the relationships between different sets of objects or groups. It consists of overlapping circles or other shapes, with each circle representing a set or group and the overlapping regions indicating the intersection of those sets. Venn diagrams are commonly used to illustrate the logical relationships and similarities/differences between different entities or concepts.                                                       \n",
    "\n",
    "In a Venn diagram, the elements or members of each set are represented by points or regions within the respective circles. The overlapping regions represent the elements that belong to multiple sets or have common characteristics.\n",
    "\n",
    "Venn diagrams can be used to visualize various concepts, such as:                                                       \n",
    "\n",
    "Set Theory: Venn diagrams are often used to represent the relationships between sets, such as the union, intersection, and complement of sets. The overlapping regions show the elements that satisfy certain conditions or belong to multiple sets.                                                                                                                   \n",
    "\n",
    "Logic and Boolean Operations: Venn diagrams can illustrate logical relationships using Boolean operators like AND, OR, and NOT. The overlapping regions indicate the combinations of conditions or propositions that are true or false.       \n",
    "\n",
    "Comparisons and Classifications: Venn diagrams can be used to compare and classify different entities or groups based on shared characteristics or attributes. They can help identify similarities and differences between the groups being compared.                                                                                                               \n",
    "\n",
    "Venn diagrams provide a clear and intuitive visual representation that helps in understanding relationships and concepts. They are widely used in mathematics, logic, statistics, and various other fields to analyze, categorize, and represent information in a structured and visual manner.                                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5def0d50-6c75-4942-af4b-a41e83ca0954",
   "metadata": {},
   "source": [
    "7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd195a-3618-4868-86ad-f86a6803b4c9",
   "metadata": {},
   "source": [
    "(i) A ∩ B = {2, 6}                                                                                                     \n",
    "(ii) A ∪ B = {0, 2, 3, 4, 5, 6, 7, 8, 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9418d79-ff2e-4a89-9436-99a146fffd1c",
   "metadata": {},
   "source": [
    "8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd1d8a1-ebe5-41af-9e62-0a52a7eee67d",
   "metadata": {},
   "source": [
    "Skewness is a statistical measure that describes the asymmetry or lack of symmetry in a probability distribution or dataset. It provides insights into the shape and distribution of the data.                                             \n",
    "\n",
    "Skewness measures the degree and direction of the skew or departure from symmetry. It indicates whether the data is skewed to the left (negatively skewed), skewed to the right (positively skewed), or approximately symmetrical (no skewness).                                                                                                             \n",
    "\n",
    "In a negatively skewed distribution, the tail of the distribution is longer on the left side, and the majority of the data is concentrated on the right side. This means that the mean is typically less than the median, and the distribution has a longer left tail.                                                                                   \n",
    "\n",
    "In a positively skewed distribution, the tail of the distribution is longer on the right side, and the majority of the data is concentrated on the left side. In this case, the mean is typically greater than the median, and the distribution has a longer right tail.                                                                                   \n",
    "\n",
    "When the distribution is approximately symmetrical, the skewness is close to zero, indicating that the data is evenly distributed around the mean, and the left and right tails are roughly equal in length.                                 \n",
    "\n",
    "Skewness is a useful measure as it provides information about the shape and characteristics of the data distribution beyond the central tendency measures (mean, median, mode). It can help identify departures from normality, understand the underlying data patterns, and guide appropriate data analysis and modeling techniques.                             \n",
    "\n",
    "Skewness can be calculated using various statistical formulas, such as Pearson's first coefficient of skewness or the moment coefficient of skewness. These formulas quantify the departure from symmetry by considering the moments or moments around the mean of the data.                                                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c330686c-745d-4513-ae73-6dde579ad42a",
   "metadata": {},
   "source": [
    "9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c283e443-1bbf-4a01-ab4c-0ef668158d63",
   "metadata": {},
   "source": [
    "If a data set is right skewed, the position of the median with respect to the mean will typically be to the left of the mean.                                                                                                                   \n",
    "\n",
    "In a right-skewed distribution, the tail of the distribution extends towards higher values, while the majority of the data is concentrated on the left side. This results in a longer right tail and a concentration of values on the lower end of the scale.                                                                                                       \n",
    "\n",
    "As a result, the mean is influenced by the larger values in the right tail, pulling it towards the higher end. The median, on the other hand, is less affected by extreme values and outliers, as it represents the middle value when the data is arranged in ascending or descending order.                                                                     \n",
    "\n",
    "Since the right-skewed distribution has a longer right tail, the median will generally be smaller than the mean. This is because the median tends to be pulled towards the lower values, closer to the majority of the data points.           \n",
    "\n",
    "Therefore, in a right-skewed distribution:                                                                             \n",
    "\n",
    "The mean will be larger than the median.                                                                               \n",
    "The median will be positioned to the left of the mean.                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026cfeb2-fa65-4ebb-a05d-e76bc1a8708d",
   "metadata": {},
   "source": [
    "10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debc0bad-bde8-477a-82f7-6d272cad915d",
   "metadata": {},
   "source": [
    "Covariance and correlation are both measures used to quantify the relationship between two variables in statistical analysis. While they are related, there are important differences between them.                                         \n",
    "\n",
    "Covariance:                                                                                                             \n",
    "Covariance measures how two variables vary together. It measures the extent to which changes in one variable are associated with changes in another variable. Covariance can take positive, negative, or zero values. A positive covariance indicates a positive relationship, meaning that as one variable increases, the other variable tends to increase as well. A negative covariance indicates a negative relationship, meaning that as one variable increases, the other variable tends to decrease. A covariance of zero indicates no linear relationship between the variables.         \n",
    "\n",
    "The formula to calculate covariance for a sample is:                                                                   \n",
    "Cov(X, Y) = Σ((Xᵢ - X̄)(Yᵢ - Ȳ)) / (n - 1)                                                                               \n",
    "\n",
    "Correlation:                                                                                                           \n",
    "Correlation is a standardized measure of the linear relationship between two variables. It indicates both the strength and the direction of the relationship. Correlation values range from -1 to 1. A correlation of 1 indicates a perfect positive relationship, a correlation of -1 indicates a perfect negative relationship, and a correlation of 0 indicates no linear relationship.                                                                                                 \n",
    "\n",
    "The formula to calculate the correlation coefficient (Pearson's correlation) for a sample is:                           \n",
    "r = Cov(X, Y) / (sX * sY)                                                                                               \n",
    "\n",
    "where Cov(X, Y) is the covariance between X and Y, sX is the standard deviation of X, and sY is the standard deviation of Y.                                                                                                                   \n",
    "\n",
    "Differences and Usage:                                                                                                 \n",
    "The main differences between covariance and correlation are:                                                           \n",
    "\n",
    "Covariance is not standardized, so its value depends on the scales of the variables being measured, whereas correlation is standardized, ranging from -1 to 1, making it easier to interpret.                                                   \n",
    "Covariance measures the strength and direction of the linear relationship, but it does not indicate the strength of the relationship independent of the scales of the variables.                                                               \n",
    "Correlation not only indicates the direction and strength of the linear relationship but also provides information about the degree to which the variables are related, regardless of their scales.                                       \n",
    "In statistical analysis, covariance and correlation are used to:                                                       \n",
    "\n",
    "Understand the relationship between variables: Both measures help assess the degree of association or dependency between two variables                                                                                                   \n",
    "Predict and model relationships: Covariance and correlation are used in regression analysis and predictive modeling to identify and quantify the relationships between predictor variables and the response variable.                         \n",
    "Feature selection: Correlation is often used to identify highly correlated features in a dataset, which can aid in selecting the most informative variables for modeling and reducing redundancy.                                         \n",
    "Assess risk and diversification: Covariance is used in portfolio management to analyze the relationships between different assets and assess their diversification benefits.                                                             \n",
    "Validate statistical models: Correlation is used to validate assumptions in linear regression models, such as checking for multicollinearity among predictors.                                                                                 \n",
    "Overall, covariance and correlation provide valuable information about the relationship between variables and are extensively used in statistical analysis for data exploration, modeling, and inference.                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b98e70-dfe9-4f1b-99c7-538b9e9f161e",
   "metadata": {},
   "source": [
    "11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4abdb9-fd31-46db-86a8-f04ab2bc3468",
   "metadata": {},
   "source": [
    "The formula for calculating the sample mean, denoted as x̄ (pronounced \"x-bar\"), is the sum of all the values in the dataset divided by the total number of values.                                                                         \n",
    "\n",
    "The formula for the sample mean is:                                                                                     \n",
    "\n",
    "x̄ = (x₁ + x₂ + x₃ + ... + xₙ) / n                                                                                       \n",
    "\n",
    "Where:                                                                                                                 \n",
    "\n",
    "x̄ is the sample mean                                                                                                   \n",
    "x₁, x₂, x₃, ..., xₙ are the individual values in the dataset                                                           \n",
    "n is the total number of values in the dataset                                                                         \n",
    "Let's calculate the sample mean for a dataset as an example:                                                           \n",
    "\n",
    "Consider the dataset: [10, 12, 14, 16, 18]                                                                             \n",
    "\n",
    "To calculate the sample mean, we sum up all the values and divide by the total number of values:                       \n",
    "\n",
    "x̄ = (10 + 12 + 14 + 16 + 18) / 5                                                                                       \n",
    "\n",
    "x̄ = 70 / 5                                                                                                             \n",
    "\n",
    "x̄ = 14                                                                                                                 \n",
    "\n",
    "Therefore, the sample mean for the given dataset is 14.                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b27323-630a-44e5-be2e-16ae65c4d72a",
   "metadata": {},
   "source": [
    "12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20379682-9e6d-4c23-ac08-d98e438d920b",
   "metadata": {},
   "source": [
    "For a normal distribution, the three measures of central tendency—mean, median, and mode—are all equal to each other. In other words, they have the same value.                                                                               \n",
    "\n",
    "This property holds true for any perfectly symmetrical distribution, such as the bell-shaped normal distribution. In a normal distribution, the data is symmetrically distributed around the mean, resulting in a balanced distribution where the mean, median, and mode coincide at the same value.                                                                 \n",
    "\n",
    "The mean represents the arithmetic average of the data and is calculated by summing all the values and dividing by the total number of observations. The median represents the middle value when the data is arranged in ascending or descending order. The mode represents the value or values that appear most frequently in the data.                     \n",
    "\n",
    "Due to the symmetry of the normal distribution, the mean, median, and mode are all located at the peak or center of the distribution, and they have the same value.                                                                             \n",
    "\n",
    "It's important to note that in real-world datasets, there may be slight deviations from perfect symmetry due to various factors or sampling issues. However, as long as the distribution closely approximates a normal distribution, the mean, median, and mode will still be relatively close to each other.                                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86cc7af-9519-42f1-a2a4-30273c39b268",
   "metadata": {},
   "source": [
    "13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b50c805-430c-4ed6-aa2f-c490a69e7e15",
   "metadata": {},
   "source": [
    "Covariance and correlation are both measures used to quantify the relationship between two variables, but they differ in a few important aspects:                                                                                             \n",
    "\n",
    "Definition:                                                                                                             \n",
    "\n",
    "Covariance measures how two variables vary together. It indicates the direction (positive or negative) and the strength of the linear relationship between two variables.                                                                       \n",
    "Correlation, specifically Pearson's correlation coefficient, is a standardized measure of the linear relationship between two variables. It quantifies both the strength and the direction of the relationship.                           \n",
    "Scale:                                                                                                                 \n",
    "\n",
    "Covariance is not standardized and its value is dependent on the scales of the variables being measured. As a result, it is challenging to compare covariance values across different datasets or variables with different units.             \n",
    "Correlation is standardized, ranging from -1 to 1. This allows for easier interpretation and comparison across different datasets and variables, regardless of their scales.                                                           \n",
    "Interpretation:                                                                                                         \n",
    "\n",
    "Covariance is measured in the units of the variables being measured. Therefore, the magnitude of covariance is difficult to interpret directly without considering the scales of the variables.                                       \n",
    "Correlation ranges from -1 to 1, with 1 indicating a perfect positive linear relationship, -1 indicating a perfect negative linear relationship, and 0 indicating no linear relationship. This standardized scale allows for a straightforward interpretation of the strength and direction of the relationship between variables.                     \n",
    "Normalization:                                                                                                         \n",
    "\n",
    "Covariance is not normalized and can take on any value, positive or negative, depending on the data. The magnitude of covariance is influenced by the scales of the variables.                                                               \n",
    "Correlation is normalized, as it is calculated by dividing the covariance by the product of the standard deviations of the variables. This normalization ensures that correlation values are always between -1 and 1, regardless of the scales of the variables.                                                                                                                                                                                                            \n",
    "Use:                                                                                                                                                                                                                                     \n",
    "\n",
    "Covariance is useful for understanding the direction and strength of the relationship between two variables. It is used in various statistical calculations and modeling techniques, such as linear regression, portfolio analysis, and analysis of variance (ANOVA).                                                                                          \n",
    "Correlation is widely used for examining and quantifying the linear relationship between variables. It is used in similar applications as covariance but provides a more standardized and interpretable measure of the relationship.\n",
    "In summary, covariance and correlation are related measures of the relationship between variables. However, covariance provides a measure of the direction and strength without standardization, while correlation provides a standardized measure of the linear relationship, allowing for easier interpretation and comparison across different datasets and variables.                                                                                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca9de89-c966-4e11-8785-227f3397ae52",
   "metadata": {},
   "source": [
    "14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1f6483-86b9-4b25-88ac-00040a6d42fd",
   "metadata": {},
   "source": [
    "Outliers can have a significant impact on measures of central tendency (such as the mean, median, and mode) and measures of dispersion (such as the range, variance, and standard deviation). Their presence can skew these measures and give a distorted representation of the data.                                                                       \n",
    "\n",
    "Measures of Central Tendency:                                                                                           \n",
    "Mean: Outliers can heavily influence the mean. Since the mean is calculated by summing all values and dividing by the total count, outliers with extreme values can significantly pull the mean in their direction.                           \n",
    "Median: The median is less affected by outliers compared to the mean. It represents the middle value when the data is arranged in ascending or descending order. Outliers have minimal effect on the median as they do not influence its position as much.                                                                                                       \n",
    "Mode: The mode, representing the most frequently occurring value(s) in the dataset, is generally not affected by outliers since it is based on the frequency of values rather than their magnitudes.                                     \n",
    "Example:                                                                                                               \n",
    "Consider the dataset: [10, 12, 14, 16, 18, 100]                                                                         \n",
    "\n",
    "Mean: The presence of the outlier \"100\" significantly affects the mean calculation. The mean without the outlier would be (10 + 12 + 14 + 16 + 18) / 5 = 14, while including the outlier results in a mean of (10 + 12 + 14 + 16 + 18 + 100) / 6 ≈ 29. Therefore, the outlier \"100\" substantially skews the mean upwards.                                             \n",
    "Median: The median is less affected by outliers. In this case, the median remains the same, as it is the middle value, which is 14, regardless of the presence of the outlier \"100\".                                                           \n",
    "Mode: The mode is unaffected by outliers since it is determined by the most frequently occurring value(s) in the dataset. In this example, the mode remains the same as well, as there are no changes in the frequencies of the other values.                                                                                                                 \n",
    "Measures of Dispersion:                                                                                                 \n",
    "Range: Outliers can greatly impact the range as they can stretch the spread of the data. The range is the difference between the maximum and minimum values in the dataset, so extreme outliers can increase the range significantly.       \n",
    "Variance and Standard Deviation: Outliers can substantially influence the variance and standard deviation. These measures quantify the average deviation of each data point from the mean. Outliers with large deviations from the mean can increase the variance and standard deviation, indicating greater dispersion in the data.                           \n",
    "Example:                                                                                                               \n",
    "Consider the dataset: [10, 12, 14, 16, 18, 100]                                                                         \n",
    "\n",
    "Range: The range is affected by the outlier \"100\". The range without the outlier would be 18 - 10 = 8, whereas including the outlier results in a range of 100 - 10 = 90. The outlier significantly expands the range.                 \n",
    "Variance and Standard Deviation: The presence of the outlier \"100\" increases the variance and standard deviation. Without the outlier, both measures would be relatively small, indicating less dispersion. However, with the outlier included, the measures increase significantly, reflecting a greater spread and deviation of data points from the mean.\n",
    "Overall, outliers can heavily influence measures of central tendency, particularly the mean, and can affect measures of dispersion, such as the range, variance, and standard deviation. It is important to consider outliers when interpreting these measures to avoid distorted conclusions about the dataset.                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbb80f1-cf27-4bdd-ab4f-5cf84a838745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
